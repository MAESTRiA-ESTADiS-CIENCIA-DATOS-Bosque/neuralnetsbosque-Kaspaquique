{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMgGg4bQovlD"
      },
      "source": [
        "#**PyTorch I**\n",
        "Autor: Jheremy Reyes,\n",
        "\n",
        "estudiante de matemáticas,\n",
        "\n",
        "Universidad El Bosque\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmQiWOLlo_Ys"
      },
      "source": [
        "**Introducción:**\n",
        "\n",
        "PyTorch es un framework de deep learning desarrollado por Facebook AI Research (FAIR) y lanzado en 2016. Su origen se basa en Torch, una biblioteca previa escrita en Lua, pero PyTorch fue diseñado para aprovechar la flexibilidad y eficiencia de Python. Desde su lanzamiento, ha ganado popularidad por su enfoque dinámico en la construcción de modelos de redes neuronales, permitiendo la creación de grafos computacionales en tiempo real, lo que facilita la depuración y experimentación. Gracias a su facilidad de uso y compatibilidad con bibliotecas científicas como NumPy, se ha convertido en una de las principales herramientas en el campo del aprendizaje profundo, compitiendo directamente con TensorFlow y siendo ampliamente adoptado en investigación y producción."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Historia:**\n",
        "\n",
        "Los Orígenes: Torch y el Nacimiento de PyTorch (2002-2016)\n",
        "La historia de PyTorch comienza con Torch, una biblioteca de computación científica escrita en Lua, creada en 2002 por Ronan Collobert, Samy Bengio y Johnny Mariéthoz. Torch fue pionera en el uso de tensores y redes neuronales, pero su dependencia de Lua limitó su adopción en una comunidad científica que prefería Python.\n",
        "\n",
        "En 2016, el equipo de investigación en inteligencia artificial de Facebook (ahora Meta), liderado por Soumith Chintala, Adam Paszke y otros, decidió crear una versión de Torch integrada con Python. Así nació PyTorch, diseñada para ser:\n",
        "\n",
        "Python-friendly: Integrada con el ecosistema científico de Python (NumPy, SciPy). Dinámica: Usaba un enfoque de \"gráficos de cálculo dinámicos\" (contrario al estático de TensorFlow), permitiendo mayor flexibilidad en redes neuronales. GPU-acelerada: Apoyada en bibliotecas como CUDA para cómputo paralelo. El lanzamiento oficial fue en octubre de 2016, con la versión 0.1.0.\n",
        "\n",
        "**El Ascenso: Adopción en la Investigación (2017-2018):**\n",
        "\n",
        "PyTorch ganó popularidad rápidamente en la comunidad académica y de investigación debido a: Facilidad de depuración: Los gráficos dinámicos permitían usar herramientas estándar de Python (como pdb). Soporte para autograd: Cálculo automático de gradientes con torch.autograd. API intuitiva: Similar a NumPy, pero con soporte para GPU.\n",
        "\n",
        "En 2018, PyTorch 1.0 marcó un hito al integrar ONNX (Open Neural Network Exchange) para interoperabilidad con otros frameworks y mejorar su uso en producción. También se lanzó TorchScript, permitiendo convertir modelos a un formato estático para despliegue.\n",
        "\n",
        "\n",
        "**Consolidación y PyTorch 2.0 (2021-Presente):**\n",
        "\n",
        "En 2021, PyTorch se convirtió en proyecto de la Linux Foundation, asegurando su neutralidad y crecimiento comunitario. La versión 2.0 (2022) trajo:\n",
        " torch.compile: Para optimizar modelos automáticamente. Mejoras en rendimiento: Hasta un 30-40% más rápido en GPUs modernas. Integración con móviles y edge computing. Hoy, PyTorch es el framework líder en IA, usado por empresas como OpenAI, Tesla y NVIDIA, y es la base de modelos como GPT-3 y Stable Diffusion."
      ],
      "metadata": {
        "id": "fWKaadQ8eI3o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_xQWmzWpaNL"
      },
      "source": [
        "**Instalación en Colab**\n",
        "PyTorch se puede instalar fácilmente en Google Colab utilizando pip. A continuación, se muestra cómo hacerlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOQZ9oIdo26h"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n18iG3QkqDp-"
      },
      "source": [
        "##**Definiciones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F94KUoCTqJ8q"
      },
      "source": [
        "**Tensores en PyTorch**\n",
        "\n",
        "Los tensores son la estructura de datos fundamental en PyTorch, similar a los arrays en NumPy. A continuacion se va a crear algunos tensores y a realizar operaciones básicas con ellos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve_sCV9WqT1n"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creación de un tensor vacío:** El código x = torch.empty(5, 3) crea un tensor bidimensional de 5 filas y 3 columnas sin inicializar, lo que significa que contendrá valores residuales de memoria (aleatorios). Esto es útil para reservar espacio antes de asignar datos específicos. Al imprimirlo con print(\"Tensor vacío:\\n\", x), verás números sin significado, que varían cada vez que se ejecuta, reflejando la naturaleza no inicializada del tensor. Es como obtener un bloc de notas con líneas dibujadas pero sin contenido escrito."
      ],
      "metadata": {
        "id": "JyFMOiIJgdno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FBUjMXtqfS0",
        "outputId": "3dafacac-170b-421b-9004-1e2a8d6977c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor vacío:\n",
            " tensor([[0.0000e+00, 0.0000e+00, 7.7052e+31],\n",
            "        [7.2148e+22, 1.5766e-19, 1.0256e-08],\n",
            "        [1.0255e-08, 3.1644e+12, 6.7735e-10],\n",
            "        [4.1962e-08, 2.6952e-09, 1.2681e+16],\n",
            "        [2.1707e-18, 7.0952e+22, 1.7748e+28]])\n"
          ]
        }
      ],
      "source": [
        "# Crear un tensor vacío\n",
        "x = torch.empty(5, 3)\n",
        "print(\"Tensor vacío:\\n\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor con valores aleatorios:** El código x = torch.rand(5, 3) genera un tensor de 5 filas y 3 columnas lleno de valores aleatorios uniformemente distribuidos entre 0 y 1. Esta operación es fundamental para inicializar pesos en redes neuronales o simular datos de prueba. Al imprimir el tensor (print(\"\\nTensor con valores aleatorios:\\n\", x)), observarás números decimales como 0.4278 o 0.9625, diferentes en cada ejecución, ya que se muestrean aleatoriamente. Es equivalente a agitar un cubo lleno de números entre 0 y 1 y volcarlos en una tabla estructurada."
      ],
      "metadata": {
        "id": "VCD9J1VPgq5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzENULsRqjc0",
        "outputId": "b94c1a64-f7f1-438f-80d2-bd3315ad4448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tensor con valores aleatorios:\n",
            " tensor([[0.6656, 0.0441, 0.4735],\n",
            "        [0.9223, 0.3219, 0.6315],\n",
            "        [0.3915, 0.0855, 0.6092],\n",
            "        [0.1036, 0.5217, 0.3545],\n",
            "        [0.2757, 0.4330, 0.1488]])\n"
          ]
        }
      ],
      "source": [
        "# Crear un tensor con valores aleatorios\n",
        "x = torch.rand(5, 3)\n",
        "print(\"\\nTensor con valores aleatorios:\\n\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDiwGv-MqoFT",
        "outputId": "3de69977-0aa7-4b0c-96af-8d3fdc53afc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tensor de ceros:\n",
            " tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "# Crear un tensor lleno de ceros\n",
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(\"\\nTensor de ceros:\\n\", x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7DCtDAEqrTF",
        "outputId": "09727e38-ae3e-45c9-96f2-b8dc03685fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tensor a partir de una lista:\n",
            " tensor([5.5000, 3.0000])\n"
          ]
        }
      ],
      "source": [
        "# Crear un tensor a partir de una lista\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(\"\\nTensor a partir de una lista:\\n\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LZKUZCegUFB"
      },
      "source": [
        "**Como importar las librerias**\n",
        "\n",
        "Estas tres líneas son el ABC del deep learning y la computación científica en Python. Cada librería cumple un rol clave:\n",
        "\n",
        "**torch**: El corazón de PyTorch, que proporciona tensores (similares a los arrays de NumPy) con superpoderes: cálculo automático de gradientes (para backpropagation) y aceleración por GPU. Sin ella, no habría redes neuronales eficientes.\n",
        "\n",
        "**numpy as np:** La biblioteca fundamental para operaciones numéricas. PyTorch se integra con NumPy (ej. torch.from_numpy()) para convertir datos entre ambos formatos. Es el \"lenguaje común\" de la ciencia de datos.\n",
        "\n",
        "**matplotlib.pyplot as plt:** La herramienta estándar para visualización. Desde graficar curvas de entrenamiento hasta mostrar imágenes (como tensores), Matplotlib hace visible lo abstracto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODw-i8gUgkhZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0t30RDVgr1X"
      },
      "source": [
        "**Eager Execution vs. Graph Execution en PyTorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch utiliza por defecto el modo Eager Execution (ejecución ávida), que evalúa las operaciones inmediatamente a medida que se escriben, sin necesidad de construir un grafo computacional estático previamente. Esto hace que el código sea más intuitivo y fácil de depurar, similar a trabajar con NumPy.\n",
        "\n",
        "a y b: Son tensores escalares (de un solo valor) creados con torch.tensor().\n",
        "\n",
        "c = a * b: La multiplicación se ejecuta al instante, mostrando que PyTorch opera de manera dinámica.\n",
        "\n",
        "Salida: El resultado 12.0 se obtiene directamente, demostrando la naturaleza interactiva de PyTorch"
      ],
      "metadata": {
        "id": "1VzZR5NHhfTE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvrELILxgvom",
        "outputId": "be1f923e-b569-47e6-b7d1-f9f0a5957611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Eager Execution en PyTorch ===\n",
            "Resultado de la multiplicación: 12.0\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Eager Execution en PyTorch ===\")\n",
        "a = torch.tensor(3.0)\n",
        "b = torch.tensor(4.0)\n",
        "c = a * b\n",
        "print(f\"Resultado de la multiplicación: {c}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9foJ_Rbg-OE"
      },
      "source": [
        "**Función decorada en PyTorch con torch.jit.script**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código demuestra cómo convertir una función de PyTorch en un grafo computacional estático usando @torch.jit.script, una característica clave para optimización y despliegue de modelos.\n",
        "\n",
        "**@torch.jit.script:**\n",
        "\n",
        "Este decorador convierte automáticamente la función Python en un formato intermedio (TorchScript) que puede ser optimizado.\n",
        "\n",
        "A diferencia del Eager Execution, aquí se crea un grafo de operaciones fijo que permite mayor eficiencia.\n",
        "\n",
        "**Función multiply_tensors:**\n",
        "\n",
        "Aunque parece una función Python normal, el decorador la transforma en una operación compilada.\n",
        "\n",
        "Soporta un subconjunto de Python, enfocado en operaciones tensoriales.\n",
        "\n",
        "**Ventajas del modo gráfico:**\n",
        "\n",
        "- Optimización: El grafo estático permite fusionar operaciones y otras optimizaciones.\n",
        "\n",
        "- Portabilidad: El modelo puede ejecutarse sin dependencia de Python (útil para producción).\n",
        "\n",
        "- Paralelización: Mejor aprovechamiento de hardware al predefinir el flujo de datos."
      ],
      "metadata": {
        "id": "dAGkFxpshs0X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvAWPTBthBUI",
        "outputId": "021acc46-4755-47db-e504-7ae6aef5aa58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Graph Execution con torch.jit.script ===\n",
            "Resultado usando torch.jit.script: 10.0\n"
          ]
        }
      ],
      "source": [
        "@torch.jit.script\n",
        "def multiply_tensors(x, y):\n",
        "    return x * y\n",
        "\n",
        "print(\"\\n=== Graph Execution con torch.jit.script ===\")\n",
        "x = torch.tensor(2.0)\n",
        "y = torch.tensor(5.0)\n",
        "print(f\"Resultado usando torch.jit.script: {multiply_tensors(x, y)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-owKUAPPhNsC"
      },
      "source": [
        "**Tensores y rangos en PyTorch (visualización)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta demostración ilustra cómo los tensores en PyTorch pueden adoptar diferentes dimensiones (rangos), desde escalares hasta matrices multidimensionales:\n",
        "\n",
        "**Definición de formas:**\n",
        "\n",
        "- (2,): Tensor 1D (vector) con 2 elementos\n",
        "\n",
        "- (2, 3): Tensor 2D (matriz) de 2 filas × 3 columnas\n",
        "\n",
        "- (2, 3, 4): Tensor 3D (cubo) con 2 matrices de 3×4\n",
        "\n",
        "**Generación de tensores:**\n",
        "\n",
        "- Cada tensor se crea con valores aleatorios usando torch.rand()\n",
        "\n",
        "- El bucle enumerate itera mostrando cada tensor numerado"
      ],
      "metadata": {
        "id": "gv7joisFkmm-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg8KiV4ZhRx_",
        "outputId": "bf66a28c-0431-4b80-99d5-27af1e681136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Tensores y Rangos en PyTorch ===\n",
            "Tensor 1 con shape (2,):\n",
            "tensor([0.6284, 0.9261])\n",
            "\n",
            "Tensor 2 con shape (2, 3):\n",
            "tensor([[0.4900, 0.4431, 0.7542],\n",
            "        [0.9790, 0.2763, 0.4437]])\n",
            "\n",
            "Tensor 3 con shape (2, 3, 4):\n",
            "tensor([[[0.2375, 0.1809, 0.2105, 0.6151],\n",
            "         [0.3429, 0.1849, 0.6998, 0.3539],\n",
            "         [0.5158, 0.5628, 0.7717, 0.7283]],\n",
            "\n",
            "        [[0.8913, 0.3701, 0.6374, 0.1888],\n",
            "         [0.6681, 0.9023, 0.8361, 0.0052],\n",
            "         [0.5938, 0.2579, 0.9376, 0.1370]]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def visualize_tensor_shapes():\n",
        "    shapes = [(2,), (2, 3), (2, 3, 4)]\n",
        "    for i, shape in enumerate(shapes, 1):\n",
        "        tensor = torch.rand(shape)\n",
        "        print(f\"Tensor {i} con shape {shape}:\\n{tensor}\\n\")\n",
        "\n",
        "print(\"\\n=== Tensores y Rangos en PyTorch ===\")\n",
        "visualize_tensor_shapes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFVdi3xThglZ"
      },
      "source": [
        "**Conversión de Tensor a Numpy array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQdDhkdhhoNJ",
        "outputId": "cee88b81-2a63-4311-fd5e-aa988b412c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Conversión a Numpy Array ===\n",
            "Tensor: tensor([1., 2., 3.])\n",
            "Numpy Array: [1. 2. 3.]\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "numpy_array = tensor.numpy()\n",
        "print(\"\\n=== Conversión a Numpy Array ===\")\n",
        "print(f\"Tensor: {tensor}\")\n",
        "print(f\"Numpy Array: {numpy_array}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conceptos clave:**\n",
        "\n",
        "- Rango (rank): Número de dimensiones (1D, 2D, 3D...)\n",
        "\n",
        "- Shape (forma): Tupla que especifica el tamaño en cada dimensión\n",
        "\n",
        "- Visualización: Tensores 3D+ se muestran por niveles/anidados"
      ],
      "metadata": {
        "id": "RZ_g-OXLlFZP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWGNbWr9hp1j"
      },
      "source": [
        "**Visualización de un tensor en 2D**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código muestra cómo visualizar un tensor bidimensional como un mapa de calor, una técnica fundamental para entender la distribución de valores en matrices:\n",
        "\n",
        "**Creación del Tensor:**\n",
        "\n",
        "torch.rand(5, 5) genera una matriz 5×5 con valores aleatorios entre 0 y 1\n",
        "\n",
        "Cada valor representa una intensidad diferente en el mapa de calor\n",
        "\n",
        "**Conversión y Visualización:**\n",
        "\n",
        ".numpy() convierte el tensor PyTorch a un array NumPy (requerido por Matplotlib)\n",
        "\n",
        "cmap='viridis' usa la paleta de colores Viridis (perceptualmente uniforme)\n",
        "\n",
        "colorbar() añade una leyenda que mapea colores a valores numéricos\n",
        "\n",
        "**Elementos del Gráfico:**\n",
        "\n",
        "Cada celda muestra un color según su valor (azul oscuro ≈ 0, amarillo ≈ 1)\n",
        "\n",
        "El eje X/Y representa los índices de la matriz (0 a 4 en este caso)"
      ],
      "metadata": {
        "id": "PAv76RgklY-7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "kzXbjE68h5EF",
        "outputId": "e18a7d03-6460-4582-a3ae-149b421c34e2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tensor_2d = torch.rand(5, 5)\n",
        "plt.imshow(tensor_2d.numpy(), cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.title(\"Visualización de Tensor 2D\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuGbgyMUjihR"
      },
      "source": [
        "**Escalar, Tensor 1D, 2D, 3D en PyTorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los escalares son fundamentales para:\n",
        "\n",
        "- Representar valores de pérdida (loss)\n",
        "\n",
        "- Hiperparámetros (tasa de aprendizaje)\n",
        "\n",
        "- Operaciones de reducción (mean, sum)"
      ],
      "metadata": {
        "id": "9OUmrTYUmKPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código demuestra la creación de un tensor escalar (tensor de rango 0) en PyTorch, que representa un único valor numérico:\n",
        "\n",
        "**Creación del escalar:**\n",
        "\n",
        "torch.tensor(4) crea un tensor con el valor entero 4\n",
        "\n",
        "dtype=torch.int32 especifica explícitamente el tipo de dato entero de 32 bits\n",
        "\n",
        "**Características clave:**\n",
        "\n",
        "Dimensión: 0-dimensional (sin shape)\n",
        "\n",
        "Uso típico: Pérdidas (loss), métricas, valores escalares en cálculos\n",
        "\n",
        "**Comportamiento**: Opera como un número normal en expresiones matemáticas"
      ],
      "metadata": {
        "id": "02CK-Etsl8F3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFM2wAf9jluN",
        "outputId": "28018948-cfa4-4ada-8ccd-3981009f2975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Diferentes tipos de Tensores en PyTorch ===\n",
            "Escalar: 4\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Diferentes tipos de Tensores en PyTorch ===\")\n",
        "scalar = torch.tensor(4, dtype=torch.int32)\n",
        "print(f\"Escalar: {scalar}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVIv0E1Ojuuh",
        "outputId": "4f12308e-9ec3-49f4-f9b8-7f6e41969315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector (1D Tensor): tensor([2., 3., 4.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "vector = torch.tensor([2.0, 3.0, 4.0], dtype=torch.float64)\n",
        "print(f\"Vector (1D Tensor): {vector}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMxXJeSbjz_d",
        "outputId": "4aa7c2e0-65f1-411e-b9e7-8da818779586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz (2D Tensor): tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n"
          ]
        }
      ],
      "source": [
        "matriz = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32)\n",
        "print(f\"Matriz (2D Tensor): {matriz}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código muestra cómo trabajar con tensores tridimensionales (rank 3) en PyTorch, que son estructuras fundamentales para datos como:\n",
        "\n",
        "- Secuencias temporales\n",
        "\n",
        "- Imágenes RGB (alto × ancho × canales)\n",
        "\n",
        "- Lotes (batches) de datos 2D"
      ],
      "metadata": {
        "id": "_SqGf2IZmfra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Estructura del tensor:**\n",
        "\n",
        "**Shape (3, 2, 5):** 3 matrices × 2 filas × 5 columnas\n",
        "\n",
        "**Niveles:**\n",
        "\n",
        "- Primer índice [i]: selecciona entre las 3 matrices\n",
        "\n",
        "- Segundo índice [i,j]: selecciona filas dentro de cada matriz\n",
        "\n",
        "- Tercer índice [i,j,k]: selecciona elementos específicos"
      ],
      "metadata": {
        "id": "MQWw3VfzmpOd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMIdiAXgj1Db",
        "outputId": "6bd2abde-93f0-47a0-a755-bbd6d9ad3a1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rank 3 Tensor: tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29]]])\n",
            "Última columna de cada matriz: tensor([[ 4,  9],\n",
            "        [14, 19],\n",
            "        [24, 29]])\n",
            "Segunda matriz del tensor: tensor([[10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19]])\n"
          ]
        }
      ],
      "source": [
        "rank_3_tensor = torch.tensor([\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],\n",
        "])\n",
        "print(f\"Rank 3 Tensor: {rank_3_tensor}\")\n",
        "print(f\"Última columna de cada matriz: {rank_3_tensor[:, :, 4]}\")\n",
        "print(f\"Segunda matriz del tensor: {rank_3_tensor[1, :, :]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxtBzL9pcvmm"
      },
      "source": [
        "**Propiedades**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCJKAm0OdMcu",
        "outputId": "7390068e-f34d-497b-ff93-51607f70b7c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rango (número de dimensiones): 4\n",
            "Tipo de elemento: torch.float32\n",
            "Número de ejes o dimensiones: 4\n",
            "Tamaño del tensor (shape): torch.Size([3, 2, 4, 5])\n",
            "Elementos en el eje 0 del tensor: 3\n",
            "Elementos en el último eje del tensor: 5\n",
            "Tamaño total de elementos (3*2*4*5): 120\n"
          ]
        }
      ],
      "source": [
        "# Crear un tensor de rango 4 lleno de ceros\n",
        "rank_4_tensor = torch.zeros([3, 2, 4, 5])\n",
        "\n",
        "# Propiedades del tensor\n",
        "print(\"Rango (número de dimensiones):\", len(rank_4_tensor.shape))  # Equivalente a tf.rank\n",
        "print(\"Tipo de elemento:\", rank_4_tensor.dtype)\n",
        "print(\"Número de ejes o dimensiones:\", rank_4_tensor.ndim)\n",
        "print(\"Tamaño del tensor (shape):\", rank_4_tensor.shape)\n",
        "print(\"Elementos en el eje 0 del tensor:\", rank_4_tensor.shape[0])\n",
        "print(\"Elementos en el último eje del tensor:\", rank_4_tensor.shape[-1])\n",
        "print(\"Tamaño total de elementos (3*2*4*5):\", rank_4_tensor.numel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCiqZrZtiXjT"
      },
      "source": [
        "**Variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCMdFINDiaXE",
        "outputId": "ee7d3642-9d4c-4079-a4f0-754baf3c50a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape:  torch.Size([2, 2])\n",
            "DType:  torch.float32\n",
            "As NumPy:  [[1. 2.]\n",
            " [3. 4.]]\n"
          ]
        }
      ],
      "source": [
        "# Crear un tensor en PyTorch\n",
        "my_tensor = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "\n",
        "# Convertirlo en una variable entrenable\n",
        "my_variable = torch.nn.Parameter(my_tensor)\n",
        "\n",
        "# Imprimir propiedades\n",
        "print(\"Shape: \", my_variable.shape)\n",
        "print(\"DType: \", my_variable.dtype)\n",
        "print(\"As NumPy: \", my_variable.detach().numpy())  # Se usa .detach() para evitar gradientes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX_SsKfEj2qz",
        "outputId": "4518c768-bbb1-4fb7-e0c1-3f0f79fbaa31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape:  torch.Size([4])\n",
            "DType:  torch.bool\n",
            "As NumPy:  [False False False  True]\n",
            "Shape:  torch.Size([2])\n",
            "DType:  torch.complex64\n",
            "As NumPy:  [5.+4.j 6.+1.j]\n"
          ]
        }
      ],
      "source": [
        "# Variable booleana\n",
        "bool_variable = torch.tensor([False, False, False, True], dtype=torch.bool)\n",
        "\n",
        "# Variable de números complejos\n",
        "complex_variable = torch.tensor([complex(5, 4), complex(6, 1)], dtype=torch.complex64)\n",
        "\n",
        "# Imprimir propiedades\n",
        "print(\"Shape: \", bool_variable.shape)\n",
        "print(\"DType: \", bool_variable.dtype)\n",
        "print(\"As NumPy: \", bool_variable.numpy())\n",
        "\n",
        "print(\"Shape: \", complex_variable.shape)\n",
        "print(\"DType: \", complex_variable.dtype)\n",
        "print(\"As NumPy: \", complex_variable.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvetk8NDkgND"
      },
      "outputs": [],
      "source": [
        "# Crear un tensor como Variable entrenable\n",
        "my_variable = torch.nn.Parameter(torch.tensor([0.0, 0.0, 0.0]))\n",
        "\n",
        "try:\n",
        "    # Intentar reasignar valores\n",
        "    my_variable.data.copy_(torch.tensor([1.0, 2.0, 3.0]))\n",
        "except Exception as e:\n",
        "    print(f\"{type(e).__name__}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCjl4BqFkrzH",
        "outputId": "b13e3191-a01a-461a-fda8-092d9a77c1d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([1., 2., 3.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Crear la primera variable\n",
        "my_variable = torch.nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
        "\n",
        "# Crear una segunda variable basada en la primera\n",
        "my_second_variable = torch.nn.Parameter(my_variable.clone())  # Clon independiente\n",
        "\n",
        "# Imprimir la segunda variable\n",
        "print(my_second_variable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XZ_5xL1k2Lz",
        "outputId": "ca57876e-47e9-4c56-ce4b-9d8fa1ec650b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor actualizado:\n",
            " tensor([[22.0000, 33.0000],\n",
            "        [13.3000, 17.0000]])\n"
          ]
        }
      ],
      "source": [
        "# Crear un tensor (variable)\n",
        "my_variable = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "\n",
        "# Asignar nuevos valores al tensor\n",
        "my_variable = torch.tensor([[22.0, 33.0], [13.3, 17.0]])\n",
        "\n",
        "# Imprimir el tensor actualizado\n",
        "print(\"Tensor actualizado:\\n\", my_variable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJBtwe4KlAsP",
        "outputId": "0885103a-080e-4281-957e-6bb014c706e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([1., 2., 3.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(my_second_variable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvFUcRMKlEb8",
        "outputId": "1f2707b7-fe90-4951-dda6-5ebadedeccb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.10000000149011612\n",
            "-0.20000000298023224\n",
            "-0.30000001192092896\n",
            "-0.4000000059604645\n"
          ]
        }
      ],
      "source": [
        "# Crear una variable escalar entrenable\n",
        "v = torch.nn.Parameter(torch.tensor(0.0))\n",
        "\n",
        "# Definir una función que decremente la variable\n",
        "def read_and_decrement():\n",
        "    v.data.sub_(0.1)  # Operación en el lugar\n",
        "    return v\n",
        "\n",
        "# Ejecutar la función 4 veces\n",
        "for _ in range(4):\n",
        "    print(read_and_decrement().item())  # Convertir a escalar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXl2NnOuljJD",
        "outputId": "22217ffd-547d-4f9c-e8a1-91d5353a05c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 1, 11,  3, 10,  9,  6,  7, 12])\n"
          ]
        }
      ],
      "source": [
        "# Crear el tensor variable\n",
        "v = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
        "\n",
        "# Índices de los elementos a actualizar\n",
        "indices = torch.tensor([4, 3, 1, 7])  # En PyTorch, los índices deben ser unidimensionales\n",
        "\n",
        "# Valores a asignar\n",
        "updates = torch.tensor([9, 10, 11, 12])\n",
        "\n",
        "# Actualizar los valores usando scatter_\n",
        "v = v.clone()  # Para evitar modificar el tensor original en PyTorch\n",
        "v.scatter_(0, indices, updates)\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQihUBUuqPad"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# Versión de PyTorch instalada\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XZVXPtowQb1"
      },
      "source": [
        "**Iteración**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "697oCNnzwPQ9",
        "outputId": "4a427695-3acf-4838-8257-4f29cc2ea1ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Crear tensor\n",
        "tensor1 = torch.ones((10, 2, 2))\n",
        "\n",
        "# Crear dataset equivalente a tf.data.Dataset.from_tensor_slices\n",
        "dataset1 = TensorDataset(tensor1)\n",
        "\n",
        "# Iterar sobre el dataset e imprimir los elementos\n",
        "for elem in dataset1:\n",
        "    print(elem[0].numpy())  # Convertir a NumPy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keCE_5y3wlQU"
      },
      "source": [
        "**Enumerar**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_96qZZ4OwnYF",
        "outputId": "bc0c748b-530c-4b07-a315-bf2f07f92d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 [[1. 1.]\n",
            " [1. 1.]]\n",
            "6 [[1. 1.]\n",
            " [1. 1.]]\n",
            "7 [[1. 1.]\n",
            " [1. 1.]]\n",
            "8 [[1. 1.]\n",
            " [1. 1.]]\n",
            "9 [[1. 1.]\n",
            " [1. 1.]]\n",
            "10 [[1. 1.]\n",
            " [1. 1.]]\n",
            "11 [[1. 1.]\n",
            " [1. 1.]]\n",
            "12 [[1. 1.]\n",
            " [1. 1.]]\n",
            "13 [[1. 1.]\n",
            " [1. 1.]]\n",
            "14 [[1. 1.]\n",
            " [1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "# Crear dataset en PyTorch\n",
        "tensor1 = torch.ones((10, 2, 2))\n",
        "dataset1 = TensorDataset(tensor1)\n",
        "\n",
        "# Equivalente a dataset1.enumerate(start=5)\n",
        "dataset_enu = enumerate(dataset1, start=5)\n",
        "\n",
        "# Iterar e imprimir elementos como NumPy\n",
        "for idx, element in dataset_enu:\n",
        "    print(idx, element[0].numpy())  # Convertir a NumPy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddsOdGvnw45T"
      },
      "source": [
        "**Barajar**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCY_-9wmw7et",
        "outputId": "d95adcdc-f599-443c-cbb6-8c41b9d4dcca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n",
            "[[[1. 1.]\n",
            "  [1. 1.]]]\n"
          ]
        }
      ],
      "source": [
        "# Crear dataset en PyTorch\n",
        "tensor1 = torch.ones((10, 2, 2))\n",
        "dataset1 = TensorDataset(tensor1)\n",
        "\n",
        "# Repetir el dataset 4 veces\n",
        "num_repeats = 4  # Si deseas repetir indefinidamente, usa \"None\" en un DataLoader con \"iter()\"\n",
        "dataset_repeated = ConcatDataset([dataset1] * num_repeats)\n",
        "\n",
        "# Crear DataLoader con shuffle\n",
        "dataloader = DataLoader(dataset_repeated, batch_size=1, shuffle=True)\n",
        "\n",
        "# Iterar e imprimir elementos como NumPy\n",
        "for element in dataloader:\n",
        "    print(element[0].numpy())  # Convertir a NumPy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiRxg_MGyKxo"
      },
      "source": [
        "**funcion map**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIrliGJ-yNGV",
        "outputId": "776baa6d-8adf-4425-c289-e2011cde2e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrada (x): [1 2 3 4]\n",
            "Salida (y): [2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "def dense_1_step(batch):\n",
        "    return batch[:-1], batch[1:]\n",
        "\n",
        "# Ejemplo de batch de datos (simulación)\n",
        "batch = torch.tensor([1, 2, 3, 4, 5])\n",
        "\n",
        "# Aplicamos la función\n",
        "x, y = dense_1_step(batch)\n",
        "\n",
        "print(\"Entrada (x):\", x.numpy())\n",
        "print(\"Salida (y):\", y.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESWGiCx0yhhu",
        "outputId": "bb8e31df-22e9-408e-b4cf-50366bf99ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]  =>  [2]\n",
            "[2]  =>  [3]\n",
            "[3]  =>  [4]\n",
            "[4]  =>  [5]\n"
          ]
        }
      ],
      "source": [
        "# Dataset personalizado en PyTorch\n",
        "class DenseDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - 1  # Evita el último índice fuera de rango\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.data[idx + 1]  # Simula dense_1_step()\n",
        "\n",
        "# Simulación de dataset1\n",
        "dataset1 = torch.tensor([1, 2, 3, 4, 5])  # Reemplázalo con tus datos reales\n",
        "\n",
        "# Crear dataset y dataloader\n",
        "dense_dataset = DenseDataset(dataset1)\n",
        "dataloader = DataLoader(dense_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Iterar sobre el dataset\n",
        "for features, label in dataloader:\n",
        "    print(features.numpy(), \" => \", label.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDBe65hby8Jc"
      },
      "source": [
        "**Dataset como texto .txt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u35YzWeVy-1T",
        "outputId": "61db22f4-2941-4f89-e96e-bbdc9b1a4299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "['.config', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())  # Muestra la carpeta actual\n",
        "print(os.listdir())  # Lista los archivos en la carpeta\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLg-8fQuzfHR"
      },
      "source": [
        "**Dataset en formato .csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRjvUzYXzlEg",
        "outputId": "09f6952c-2f8b-4275-aeb2-3218154872e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "['.config', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())  # Muestra la ruta actual\n",
        "print(os.listdir())  # Lista los archivos en la carpeta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Vtnb_RzAzxK-",
        "outputId": "83955de6-6067-4114-8b78-bfaef602838b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-07719e26-c1a2-4efd-a442-7cddb8be53cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-07719e26-c1a2-4efd-a442-7cddb8be53cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Te permitirá cargar archivos manualmente\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}