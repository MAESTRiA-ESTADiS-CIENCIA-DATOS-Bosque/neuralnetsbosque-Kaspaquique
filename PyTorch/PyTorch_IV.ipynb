{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**PyTorch IV**\n",
        "Autor: Jheremy Reyes,\n",
        "\n",
        "estudiante de matemáticas,\n",
        "\n",
        "Universidad El Bosque"
      ],
      "metadata": {
        "id": "CDIb21tMCSDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Listas en PyTorch: Introducción y uso práctico**"
      ],
      "metadata": {
        "id": "EFQSvKCFCs2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En PyTorch, cuando trabajamos con estructuras de datos, una confusión común —especialmente entre quienes vienen de numpy o programación pura en Python— es cómo manejar colecciones de tensores. Aunque PyTorch no tiene un tipo de dato especial llamado “lista de tensores”, el uso de listas de Python (o tuplas) para agrupar tensores es muy frecuente y fundamental para construir modelos flexibles y dinámicos.\n",
        "\n",
        "¿Por qué son importantes las listas en PyTorch?\n",
        "\n",
        "Las listas en PyTorch son esenciales para:\n",
        "\n",
        "- Agrupar tensores que representan datos o parámetros con forma o tamaño variable.\n",
        "\n",
        "- Iterar dinámicamente sobre elementos en modelos no secuenciales.\n",
        "\n",
        "- Construir redes neuronales personalizadas, donde las capas o bloques son definidos mediante estructuras dinámicas.\n",
        "\n",
        "- Realizar operaciones por lotes (batch) sobre elementos independientes sin necesidad de apilar todo en un solo tensor.\n",
        "\n",
        "En muchos contextos, usamos listas de tensores para representar estructuras como secuencias de longitudes variables (por ejemplo, en NLP), o resultados intermedios de operaciones.\n",
        "\n",
        "¿Qué es una lista de tensores?\n",
        "\n",
        "En términos simples, es una lista de Python (list) cuyos elementos son objetos tipo torch.Tensor. Esto permite almacenar múltiples tensores, ya sean del mismo tamaño o no."
      ],
      "metadata": {
        "id": "XleU4Gr1C1hO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCgQYHXnCJDH",
        "outputId": "6d0b4fdd-129a-4804-8d74-ca261091d9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([1, 2]), tensor([3, 4]), tensor([5, 6])]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Crear una lista de tensores\n",
        "lista_de_tensores = [torch.tensor([1, 2]), torch.tensor([3, 4]), torch.tensor([5, 6])]\n",
        "print(lista_de_tensores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada tensor en la lista puede ser accedido e indexado de manera individual:"
      ],
      "metadata": {
        "id": "_KLh28ohDLdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lista_de_tensores[0])  # tensor([1, 2])\n",
        "print(lista_de_tensores[1][0])  # 3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34xdPhW6DMwM",
        "outputId": "e9635529-f079-424f-e759-ce36fd0e1ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2])\n",
            "tensor(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ventajas de usar listas en PyTorch**\n",
        "\n",
        "- Flexibilidad: A diferencia de tensores apilados, no se requiere que los tensores tengan la misma forma o dimensión.\n",
        "\n",
        "- Compatibilidad con estructuras de control: Se pueden usar en bucles, condicionales y otras estructuras de programación dinámica.\n",
        "\n",
        "- Facilidad para modelar arquitecturas personalizadas, como árboles, redes recurrentes o flujos de datos no lineales."
      ],
      "metadata": {
        "id": "mER2j46UDRxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Cuándo no usar listas?**\n",
        "\n",
        "Aunque son útiles, las listas tienen limitaciones:\n",
        "\n",
        "No están integradas directamente con las operaciones vectorizadas de PyTorch, como lo están los tensores.\n",
        "\n",
        "No se pueden mover a GPU como un solo objeto. Hay que mover cada tensor individualmente.\n",
        "\n",
        "No se pueden usar directamente en funciones como loss.backward() o optimizer.step() si se espera una estructura tensorial única."
      ],
      "metadata": {
        "id": "aYmjM2V0DcY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# Versión de PyTorch instalada\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC8sE7z5DpcX",
        "outputId": "a8c09975-5d4c-4c13-dd3f-14a9f96ecc56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_examp =np.array(range(70)).reshape(7,10)\n",
        "lista_examp = array_examp.tolist()\n",
        "print(array_examp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wySK3541Dh5u",
        "outputId": "da4881c7-2972-4496-dcd7-6ff8241558b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de arrays de entrada\n",
        "array_examp = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "lista_examp = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Equivalente a tf.data.Dataset.from_tensor_slices(array_examp)\n",
        "dataset1 = torch.utils.data.TensorDataset(array_examp)\n",
        "\n",
        "# Equivalente a tf.data.Dataset.from_tensors(array_examp)\n",
        "dataset2 = [array_examp]  # En PyTorch, `from_tensors` no existe, usamos una lista con el tensor completo\n",
        "\n",
        "# Equivalente a tf.data.Dataset.from_tensor_slices(lista_examp)\n",
        "dataset_lista_1 = torch.utils.data.TensorDataset(torch.tensor(lista_examp))\n",
        "\n",
        "# Equivalente a tf.data.Dataset.from_tensors(lista_examp)\n",
        "dataset_lista_2 = [torch.tensor(lista_examp)]  # Lista con el tensor completo\n"
      ],
      "metadata": {
        "id": "JOmbZyVCDvtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos de ejemplo\n",
        "array_examp = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "lista_examp = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Crear datasets en PyTorch\n",
        "dataset1 = torch.utils.data.TensorDataset(array_examp)\n",
        "dataset2 = [array_examp]  # from_tensors equivalente\n",
        "dataset_lista_1 = torch.utils.data.TensorDataset(torch.tensor(lista_examp))\n",
        "dataset_lista_2 = [torch.tensor(lista_examp)]  # from_tensors equivalente\n",
        "\n",
        "# Función para imprimir información de los datasets\n",
        "def print_dataset_info(name, dataset):\n",
        "    print(f\"\\n{name}:\")\n",
        "    if isinstance(dataset, torch.utils.data.TensorDataset):\n",
        "        for i in range(len(dataset)):\n",
        "            print(f\"Elemento {i}: {dataset[i][0].shape}, dtype: {dataset[i][0].dtype}\")\n",
        "    elif isinstance(dataset, list):\n",
        "        print(f\"Elemento único: {dataset[0].shape}, dtype: {dataset[0].dtype}\")\n",
        "    else:\n",
        "        print(\"Tipo desconocido:\", type(dataset))\n",
        "\n",
        "# Imprimir información de los datasets\n",
        "print_dataset_info(\"Dataset1 (from_tensor_slices)\", dataset1)\n",
        "print_dataset_info(\"Dataset2 (from_tensors)\", dataset2)\n",
        "print_dataset_info(\"Dataset Lista 1 (from_tensor_slices)\", dataset_lista_1)\n",
        "print_dataset_info(\"Dataset Lista 2 (from_tensors)\", dataset_lista_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfoYtt4FDz20",
        "outputId": "9221f079-936d-4333-8e9e-01c5f7ce5a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset1 (from_tensor_slices):\n",
            "Elemento 0: torch.Size([3]), dtype: torch.int64\n",
            "Elemento 1: torch.Size([3]), dtype: torch.int64\n",
            "Elemento 2: torch.Size([3]), dtype: torch.int64\n",
            "\n",
            "Dataset2 (from_tensors):\n",
            "Elemento único: torch.Size([3, 3]), dtype: torch.int64\n",
            "\n",
            "Dataset Lista 1 (from_tensor_slices):\n",
            "Elemento 0: torch.Size([]), dtype: torch.int64\n",
            "Elemento 1: torch.Size([]), dtype: torch.int64\n",
            "Elemento 2: torch.Size([]), dtype: torch.int64\n",
            "Elemento 3: torch.Size([]), dtype: torch.int64\n",
            "Elemento 4: torch.Size([]), dtype: torch.int64\n",
            "\n",
            "Dataset Lista 2 (from_tensors):\n",
            "Elemento único: torch.Size([5]), dtype: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor con forma [10,2,2] lleno de unos\n",
        "tensor1 = torch.ones((10, 2, 2))\n",
        "\n",
        "# Tensor con forma [10,1] lleno de unos\n",
        "tensor2 = torch.ones((10, 1))\n",
        "\n",
        "# Tensor con forma [9,2,2] lleno de unos\n",
        "tensor3 = torch.ones((9, 2, 2))\n",
        "\n",
        "# Verificar formas\n",
        "print(\"tensor1 shape:\", tensor1.shape)\n",
        "print(\"tensor2 shape:\", tensor2.shape)\n",
        "print(\"tensor3 shape:\", tensor3.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gldn6ecfD3rB",
        "outputId": "9b960683-9820-44cb-b497-5e7d552ee6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor1 shape: torch.Size([10, 2, 2])\n",
            "tensor2 shape: torch.Size([10, 1])\n",
            "tensor3 shape: torch.Size([9, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear tensores\n",
        "tensor1 = torch.ones((10, 2, 2))\n",
        "tensor2 = torch.ones((10, 1))\n",
        "tensor3 = torch.ones((9, 2, 2))\n",
        "\n",
        "# Dataset equivalente a tf.data.Dataset.from_tensors((tensor1, tensor2))\n",
        "dataset5 = [ (tensor1, tensor2) ]  # from_tensors mantiene el tensor completo\n",
        "\n",
        "# Dataset equivalente a tf.data.Dataset.from_tensors((tensor1, tensor3))\n",
        "# Esto generará un error porque tensor1 tiene shape (10,2,2) y tensor3 tiene shape (9,2,2)\n",
        "# dataset6 = [ (tensor1, tensor3) ]  # Esto dará error\n",
        "\n",
        "# Imprimir forma de dataset5\n",
        "print(\"Dataset5:\", dataset5[0][0].shape, dataset5[0][1].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJBQ7aSPD7LM",
        "outputId": "f4cad1f5-adf3-4c6e-b233-49e2093b1907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset5: torch.Size([10, 2, 2]) torch.Size([10, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets equivalentes a from_tensors en TensorFlow\n",
        "dataset3 = torch.utils.data.TensorDataset(tensor1)  # Simulación de un dataset simple\n",
        "dataset5 = [(tensor1, tensor2)]  # from_tensors en TensorFlow almacena la tupla completa en un solo elemento\n",
        "dataset6 = [(tensor1[:9], tensor3)]  # Ajustamos tensor1 para que tenga el mismo tamaño que tensor3\n",
        "\n",
        "# Función para imprimir información de los datasets\n",
        "def print_dataset_info(name, dataset):\n",
        "    print(f\"\\n{name}:\")\n",
        "    if isinstance(dataset, torch.utils.data.TensorDataset):\n",
        "        print(f\"Elemento 0: {dataset[0][0].shape}, dtype: {dataset[0][0].dtype}\")\n",
        "    elif isinstance(dataset, list):\n",
        "        print(f\"Elemento único: {[t.shape for t in dataset[0]]}, dtype: {[t.dtype for t in dataset[0]]}\")\n",
        "    else:\n",
        "        print(\"Tipo desconocido:\", type(dataset))\n",
        "\n",
        "# Imprimir información de los datasets\n",
        "print_dataset_info(\"Dataset3\", dataset3)\n",
        "print_dataset_info(\"Dataset5\", dataset5)\n",
        "print_dataset_info(\"Dataset6\", dataset6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN35Q3GcD-iV",
        "outputId": "8391b890-c4e9-49fe-8497-8602d0d701c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset3:\n",
            "Elemento 0: torch.Size([2, 2]), dtype: torch.float32\n",
            "\n",
            "Dataset5:\n",
            "Elemento único: [torch.Size([10, 2, 2]), torch.Size([10, 1])], dtype: [torch.float32, torch.float32]\n",
            "\n",
            "Dataset6:\n",
            "Elemento único: [torch.Size([9, 2, 2]), torch.Size([9, 2, 2])], dtype: [torch.float32, torch.float32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Qué es un Batch en PyTorch?**"
      ],
      "metadata": {
        "id": "EYBgCi2SSWRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En aprendizaje profundo, el concepto de batch (o lote) es fundamental. Cuando entrenamos una red neuronal, no procesamos todo el conjunto de datos de una sola vez, sino que lo dividimos en partes más pequeñas llamadas batches. PyTorch implementa este mecanismo de forma flexible y eficiente, lo cual permite optimizar el rendimiento computacional y facilitar la actualización de los parámetros del modelo.\n",
        "\n",
        "**¿Por qué se usan batches?**\n",
        "\n",
        "Existen tres formas comunes de alimentar datos durante el entrenamiento:\n",
        "\n",
        "Entrenamiento por instancia (Stochastic Gradient Descent – SGD): se procesa una sola muestra a la vez.\n",
        "\n",
        "Entrenamiento por lotes (Batch Gradient Descent): se procesan todas las muestras a la vez.\n",
        "\n",
        "Entrenamiento en mini-batches (Mini-Batch Gradient Descent): se divide el conjunto de datos en pequeños grupos (mini-batches) y se entrena con cada uno secuencialmente.\n",
        "\n",
        "PyTorch utiliza principalmente el enfoque de mini-batches, que ofrece una excelente relación entre eficiencia computacional y estabilidad en el entrenamiento."
      ],
      "metadata": {
        "id": "WiSAhWv8R24_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Cómo se representa un batch en PyTorch?**\n",
        "\n",
        "Un batch de datos es simplemente un tensor con una dimensión adicional que representa cuántos ejemplos se están procesando al mismo tiempo.\n",
        "\n",
        "Por ejemplo, si estamos trabajando con imágenes en escala de grises de 28×28 píxeles:\n",
        "\n",
        "- Una sola imagen se representa como un tensor de forma (1, 28, 28) (1 canal, altura 28, ancho 28).\n",
        "\n",
        "- Un batch de 64 imágenes se representa como un tensor de forma (64, 1, 28, 28).\n",
        "\n",
        "De manera general, para cualquier tipo de datos, la primera dimensión del tensor representa el tamaño del batch:"
      ],
      "metadata": {
        "id": "qcyprm0GSdCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Supongamos que tenemos un batch de 4 vectores de 3 elementos cada uno\n",
        "batch = torch.tensor([\n",
        "    [1.0, 2.0, 3.0],   # muestra 1\n",
        "    [4.0, 5.0, 6.0],   # muestra 2\n",
        "    [7.0, 8.0, 9.0],   # muestra 3\n",
        "    [10.0, 11.0, 12.0] # muestra 4\n",
        "])\n",
        "\n",
        "print(\"Forma del batch:\", batch.shape)  # torch.Size([4, 3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYyEXtM1StZF",
        "outputId": "9287d3ab-8e5e-42d8-c1b4-e71b91bcc4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma del batch: torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí, cada fila representa una muestra, y hay 4 muestras en el batch. Este tipo de estructura es la que espera PyTorch cuando alimentamos los datos al modelo"
      ],
      "metadata": {
        "id": "GbdnDJcfS_Dj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Integración con DataLoader**"
      ],
      "metadata": {
        "id": "mUstQvKLTEzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch facilita la creación y manejo de batches a través de la clase DataLoader, que automatiza el agrupamiento y la iteración sobre los datos:"
      ],
      "metadata": {
        "id": "o1984RccTJP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Crear un conjunto de datos ficticio\n",
        "X = torch.randn(100, 10)  # 100 muestras, 10 características\n",
        "y = torch.randint(0, 2, (100,))  # 100 etiquetas binarias\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Iterar sobre los datos en batches\n",
        "for xb, yb in loader:\n",
        "    print(\"Batch de entrada:\", xb.shape)\n",
        "    print(\"Batch de etiquetas:\", yb.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovuaQVcVTKRH",
        "outputId": "7ce7c2d4-2efd-45ec-d3a0-cb55eb386062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch de entrada: torch.Size([16, 10])\n",
            "Batch de etiquetas: torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear dataset con valores de 0 a 19 (equivalente a tf.data.Dataset.range(20))\n",
        "dataset_range = torch.arange(20)\n",
        "\n",
        "# Convertirlo en un TensorDataset\n",
        "dataset_range = TensorDataset(dataset_range)\n",
        "\n",
        "# Agrupar en batches de tamaño 3 (equivalente a dataset_range.batch(3))\n",
        "dataloader = DataLoader(dataset_range, batch_size=3)\n",
        "\n",
        "# Enumerar los batches desde 0 (equivalente a dataset_range.enumerate(start=0))\n",
        "for idx, batch in enumerate(dataloader, start=0):\n",
        "    print(idx, batch[0].numpy())  # Convertir a NumPy para visualizar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83BTlQxqTQIj",
        "outputId": "efd4e056-1c60-412d-e375-feba7beb9a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [0 1 2]\n",
            "1 [3 4 5]\n",
            "2 [6 7 8]\n",
            "3 [ 9 10 11]\n",
            "4 [12 13 14]\n",
            "5 [15 16 17]\n",
            "6 [18 19]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear dataset con valores de 0 a 19 (equivalente a tf.data.Dataset.range(20))\n",
        "dataset_range = torch.arange(20)\n",
        "\n",
        "# Convertirlo en un TensorDataset\n",
        "dataset_range = TensorDataset(dataset_range)\n",
        "\n",
        "# Agrupar en batches de tamaño 3 y descartar el último lote si no tiene el tamaño completo\n",
        "dataloader = DataLoader(dataset_range, batch_size=3, drop_last=True)\n",
        "\n",
        "# Enumerar los batches desde 0 (equivalente a dataset_range.enumerate(start=0))\n",
        "for idx, batch in enumerate(dataloader, start=0):\n",
        "    print(idx, batch[0].numpy())  # Convertir a NumPy para visualizar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2JmYUPwTT1v",
        "outputId": "97f40608-1c04-4056-973e-867b101f33d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [0 1 2]\n",
            "1 [3 4 5]\n",
            "2 [6 7 8]\n",
            "3 [ 9 10 11]\n",
            "4 [12 13 14]\n",
            "5 [15 16 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import itertools\n",
        "\n",
        "# Crear dataset con valores de 0 a 19\n",
        "dataset_range = torch.arange(20)\n",
        "\n",
        "# Convertirlo en un TensorDataset\n",
        "dataset_range = TensorDataset(dataset_range)\n",
        "\n",
        "# Agrupar en batches de tamaño 3 y descartar el último lote si es incompleto\n",
        "dataloader = DataLoader(dataset_range, batch_size=3, drop_last=True)\n",
        "\n",
        "# Tomar solo los 2 primeros batches\n",
        "for idx, batch in itertools.islice(enumerate(dataloader), 2):\n",
        "    print(batch[0].numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTXF-Oa3TYyN",
        "outputId": "d2080a2b-9dc9-431c-d844-e374df7b4220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2]\n",
            "[3 4 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulación de dataset1 (debes reemplazarlo con tus datos reales)\n",
        "dataset1 = torch.arange(12)  # Suponiendo 12 elementos para ver varios lotes\n",
        "\n",
        "# Convertirlo en un TensorDataset\n",
        "dataset1 = TensorDataset(dataset1)\n",
        "\n",
        "# Crear DataLoader con batch_size=3\n",
        "dataloader = DataLoader(dataset1, batch_size=3)\n",
        "\n",
        "# Enumerar desde 0\n",
        "for idx, batch in enumerate(dataloader, start=0):\n",
        "    print(idx, batch[0].numpy())  # Convertir a NumPy para visualizar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_sCW39xTeeE",
        "outputId": "66f66a09-636c-480e-a939-6e04b94d893e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [0 1 2]\n",
            "1 [3 4 5]\n",
            "2 [6 7 8]\n",
            "3 [ 9 10 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulación de dataset1 (reemplázalo con tus datos reales)\n",
        "dataset1 = torch.arange(10)  # Suponiendo 10 elementos para la demostración\n",
        "\n",
        "# Convertir a TensorDataset\n",
        "dataset1 = TensorDataset(dataset1)\n",
        "\n",
        "# Crear DataLoader con batch_size=1\n",
        "dataloader = DataLoader(dataset1, batch_size=1)\n",
        "\n",
        "# Enumerar desde 0 (equivalente a .enumerate(start=0) en TF)\n",
        "for idx, batch in enumerate(dataloader, start=0):\n",
        "    print(idx, batch[0].numpy())  # Convertir a NumPy para visualizar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2qOQ5CuTh2b",
        "outputId": "4932bd1e-880b-43c4-8c31-6574ee77edfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [0]\n",
            "1 [1]\n",
            "2 [2]\n",
            "3 [3]\n",
            "4 [4]\n",
            "5 [5]\n",
            "6 [6]\n",
            "7 [7]\n",
            "8 [8]\n",
            "9 [9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función flat_map en PyTorch (y en programación funcional)**\n",
        "\n",
        "**¿Qué es flat_map?**\n",
        "\n",
        "Aunque PyTorch no tiene una función flat_map incorporada como tal en su API, este concepto proviene de la programación funcional, y es útil entenderlo, ya que aparece en librerías como PySpark, Kotlin, Scala, Haskell, y en paradigmas funcionales en general."
      ],
      "metadata": {
        "id": "BYpSSPYJT1vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usando map seguido de flatten (sin flat_map)\n",
        "data = [\"a,b,c\", \"d,e\"]\n",
        "mapped = map(lambda x: x.split(\",\"), data)  # [['a','b','c'], ['d','e']]\n",
        "flattened = [item for sublist in mapped for item in sublist]\n",
        "print(flattened)  # ['a', 'b', 'c', 'd', 'e']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CpGosFVT1dj",
        "outputId": "16d65a78-4e6f-471c-d57f-9366a3b9a823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'd', 'e']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_map(func, iterable):\n",
        "    return [item for sublist in map(func, iterable) for item in sublist]\n",
        "\n",
        "# Ejemplo\n",
        "data = [\"1,2\", \"3,4\"]\n",
        "result = flat_map(lambda x: x.split(\",\"), data)\n",
        "print(result)  # ['1', '2', '3', '4']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_7BLG0VUKJB",
        "outputId": "b1b74c16-1009-4853-cee6-cc86933a830c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '2', '3', '4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Cuándo se usa flat_map en ciencia de datos o PyTorch?**\n",
        "\n",
        "\n",
        "Aunque no es común en el core de PyTorch, el concepto de flat_map es útil para:\n",
        "\n",
        "- Preprocesar datasets donde una muestra se puede convertir en varias submuestras.\n",
        "\n",
        "- Procesar secuencias anidadas y convertirlas en una sola secuencia.\n",
        "\n",
        "- Transformar datos con operaciones de tokenización, ventaneo (sliding windows), o expansión temporal."
      ],
      "metadata": {
        "id": "8UE0zBwjUOo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"1,2,3\", \"4,5\", \"6\"]\n"
      ],
      "metadata": {
        "id": "P8tA-63JUXfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_tensor = torch.tensor(\n",
        "    flat_map(lambda x: list(map(int, x.split(\",\"))), data)\n",
        ")\n",
        "print(flat_tensor)  # tensor([1, 2, 3, 4, 5, 6])\n"
      ],
      "metadata": {
        "id": "urLFjn4ZUaMk",
        "outputId": "3522e2e6-0620-4c3c-c567-7fc5c5a2699c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque no sea parte directa de la API de PyTorch, entender y aplicar el patrón flat_map es muy útil para tareas complejas de preprocesamiento de datos, especialmente cuando se combinan estructuras irregulares o anidadas."
      ],
      "metadata": {
        "id": "RAM47kdBUenj"
      }
    }
  ]
}